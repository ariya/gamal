name: Prepare Small LLM
description: Download small LLM and launch it
runs:
  using: composite
  steps:
    - name: Download and unpack llama.cpp
      shell: bash
      run: |
        curl -OL https://github.com/ggerganov/llama.cpp/releases/download/b4034/llama-b4034-bin-ubuntu-x64.zip
        unzip llama-b4034-bin-ubuntu-x64.zip

    - name: Launch llama.cpp
      shell: bash
      run: ./build/bin/llama-server -c 4096 --hf-repo bartowski/Qwen2.5-1.5B-Instruct-GGUF --hf-file Qwen2.5-1.5B-Instruct-IQ4_XS.gguf &

    - name: Wait until it is ready
      shell: bash
      run: while ! curl -s 'http://localhost:8080/health' | grep 'ok'; do sleep 1; done
