name: Canary for multi-turn

on: [workflow_dispatch, push, pull_request]

jobs:

  canary-multi-turn:
    runs-on: ubuntu-22.04
    timeout-minutes: 3
    strategy:
      fail-fast: false
      matrix:
        model:
          - mistralai/mistral-7b-instruct-v0.3           # $0.07
          - meta-llama/llama-3-8b-instruct               # $0.07
          - openchat/openchat-7b                         # $0.07
          - openchat/openchat-8b                         # $0.08
          - qwen/qwen-4b-chat                            # $0.09
          - microsoft/phi-3-medium-4k-instruct           # $0.14
          - nousresearch/hermes-2-pro-llama-3-8b         # $0.15
          - teknium/openhermes-2.5-mistral-7b            # $0.17
          - nousresearch/nous-hermes-2-mistral-7b-dpo    # $0.18
          - open-orca/mistral-7b-openorca                # $0.18
          - mistralai/mixtral-8x7b-instruct              # $0.24
          - qwen/qwen-14b-chat                           # $0.27
          - meta-llama/llama-3-70b-instruct              # $0.59
          - mistralai/mixtral-8x22b-instruct             # $0.65
    steps:
      - uses: actions/checkout@v4

      - run: ./query-llm.js tests/canary-single-turn.txt
        env:
          LLM_API_BASE_URL: ${{ secrets.LLM_API_BASE_URL }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
          LLM_CHAT_MODEL: ${{ matrix.model }}

      - run: ./query-llm.js tests/canary-multi-turn.txt
        env:
          LLM_API_BASE_URL: ${{ secrets.LLM_API_BASE_URL }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
          LLM_CHAT_MODEL: ${{ matrix.model }}
